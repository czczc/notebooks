# GENIE Neutrino Interaction Models – Technical Overview

In neutrino event generators like **GENIE**, the full simulation chain is divided into stages with specific models for each physical process. Below we detail each model listed in the GENIE table, explaining the physics it represents, the theoretical basis, comparisons to alternatives, and performance against experimental data. Short bullet points highlight key aspects for clarity.

## 1. Correlated Fermi Gas (Nuclear Ground State)

**Physics Process:** This model describes the **initial nuclear ground state**, i.e. how nucleons are distributed in momentum inside the nucleus before the neutrino interacts. It extends the Fermi gas picture by including **short-range nucleon–nucleon correlations**.

**Theoretical Framework:** The **Correlated Fermi Gas (CFG)** is a variant of the Local Fermi Gas model that adds a **high-momentum tail** to the nucleon momentum distribution beyond the usual Fermi momentum (k<sub>F</sub>). In GENIE v3.2, the CFG is implemented by renormalizing the LFG distribution so that a fixed fraction of nucleons (default \~20%) occupy momenta above k<sub>F</sub>, based on electron scattering data. This tail accounts for short-range correlated nucleon pairs and is tuned to measurements (e.g. inclusive A(e,e') at x>1 shows \~20% nucleons carry momentum beyond k<sub>F</sub>). The CFG retains the spatial dependence of the LFG (nuclear density profile) while modifying the momentum distribution.

**Alternative Models:** Earlier generators often used a **Relativistic Fermi Gas (RFG)** (global Fermi momentum, no correlations) or an **LFG** (local density-dependent Fermi momentum) without extra high-momentum components. Advanced approaches like **nuclear spectral functions** explicitly include correlation effects by using momentum distributions from microscopic calculations. The CFG provides an **empirical middle ground** – adding a correlation tail to the Fermi gas – which approximates the effect of nucleon–nucleon short-range correlations without the complexity of a full spectral function model. For example, setting the CFG’s correlation fraction to 0% reverts it to a pure LFG (no high-momentum tail).

**Comparison to Data:** By construction, the CFG improves agreement with electron-nucleus scattering data that observe nucleons above the Fermi cutoff. It reproduces the high-momentum components seen in inclusive (e,e′) measurements. This leads to a more realistic initial state for neutrino interactions – e.g. neutrinos can scatter off a fast-moving nucleon pair, affecting kinematics of quasielastic (QE) and 2p2h interactions. While a pure Fermi Gas underestimates those tails, the CFG’s 20% high-momentum nucleons brings GENIE predictions closer to data. Future model tuning may adjust the tail fraction as new nuclear data emerge. (In comparison, fully theory-driven spectral function models show similar high-momentum behavior and often better predict certain observables like nucleon knock-out momentum distributions, at the cost of complexity.)

## 2. Valencia Model (Quasi-Elastic Scattering)

**Physics Process:** **Charged-Current Quasi-Elastic (CCQE)** scattering on nuclear targets (e.g. \$\nu\_\mu + n \to \mu^- + p\$ in a nucleus) is modeled by the **Valencia model** for QE. This covers single-nucleon knockout interactions where the neutrino exchanges W bosons with a nucleon, leaving only leptons and nucleons in final state (no pions). It specifically includes nuclear medium effects on the QE interaction.

**Theoretical Framework:** The Valencia QE model (developed by Nieves *et al.*) builds on the full **Llewellyn Smith** formalism for neutrino-nucleon QE cross sections but inserts detailed **nuclear many-body corrections**. It uses a Local Fermi Gas initial state consistent with the Valencia nuclear model inputs. Crucially, it applies **Random Phase Approximation (RPA)** corrections to the nuclear response, which account for long-range nucleon-nucleon correlations (screening by the nuclear medium). RPA tends to **suppress the QE cross section at low momentum transfer**, as nucleons coherently interact and reduce the probability of ejecting a single nucleon. The model also includes a proper treatment of Pauli blocking and uses non-dipole vector form factors (usually BBBA2005) and an axial form factor as tuned (see Section 3). GENIE implements Valencia QE by assigning an off-shell energy to the struck nucleon (for binding energy) and using the Valencia hadronic tensor with Coulomb corrections for leptons.

**Alternative Models:** The historical GENIE default for QE was a simpler approach: **Fermi Gas + Llewellyn Smith** formula with a dipole axial form factor (usually \$M\_A\approx0.99\$ GeV). That approach neglects nuclear coherence beyond Pauli blocking. Alternative advanced models include spectral function-based QE (e.g. Benhar’s model) or other many-body methods (e.g. the Superscaling/SuSAv2 QE model, see Section 4). The Valencia model’s distinctive feature is the RPA suppression and in-medium form factors. Other groups (e.g. Martini *et al.*) also include RPA and multi-nucleon effects, but the Valencia model is widely used and implemented in generators (GENIE, NEUT) as a standard for QE. If one were to turn **off** Valencia’s RPA, the result would resemble a higher effective axial mass (to fit data) – historically experiments like MiniBooNE did this by inflating \$M\_A\$ in a Fermi Gas model to \$\sim1.3\$ GeV to account for nuclear effects. The Valencia model provides a more direct physics-based suppression rather than an ad-hoc \$M\_A\$ tweak.

**Comparison to Data:** The Valencia QE model **improves agreement with observed QE cross sections**, especially the \$Q^2\$ distribution shape at low \$Q^2\$. Experiments on carbon and oxygen (MiniBooNE, MINERvA, T2K) showed QE cross sections lower than a naive Fermi Gas prediction in the low \$Q^2\$ region – Valencia’s RPA accurately produces this suppression. For example, MicroBooNE found that a configuration using Valencia QE with RPA gave substantially improved agreement in muon angular distributions for CC0π (QE-like) events. GENIE comprehensive tunes (e.g. G18\_10a) that include the Valencia QE model show better reproduction of absolute cross sections and muon kinematics than those using the older dipole model. There remain some discrepancies (e.g. strength of suppression or high-\$Q^2\$ normalization), but overall the Valencia model, when combined with its 2p2h extension (below), successfully reproduces many QE measurements on nuclear targets without the need to artificially adjust \$M\_A\$. The model has been tested against electron-scattering data as well, ensuring consistency in the vector part of the response.

## 3. \$Z\$-Expansion Fit to Deuterium (Nucleon Axial Form Factor)

**Physics Process:** This is not a scattering channel per se, but the model for the **nucleon’s axial form factor \$F\_A(Q^2)\$** used in calculating QE (and resonance) cross sections. The axial form factor encapsulates the nucleon’s weak structure (analogous to the well-known electromagnetic form factors). GENIE by default uses a dipole parameterization with axial mass \$M\_A\approx0.99\$ GeV, but an alternative is a data-driven **\$z\$-expansion fit**.

**Theoretical Framework:** The **\$z\$-expansion** is a modern, model-independent method to parametrize form factors based on analytical properties (analytic continuation and conformal mapping of \$Q^2\$). Instead of assuming a specific shape (dipole), one expands \$F\_A\$ as a power series in a variable \$z(Q^2)\$ that maps the physical \$Q^2\$ domain into \$|z|<1\$ for convergence. Coefficients of the polynomial are fit to experimental data with constraints (like known \$F\_A(0)=g\_A=1.2723\$ and ensuring proper high-\$Q^2\$ falloff via sum rules). GENIE incorporates a \$z\$-expansion fit performed by Meyer *et al.* (2016) using neutrino scattering on **deuterium** (quasi-free \$np\$ target). This fit does not force a dipole shape and includes systematic uncertainties of the data. The result is a series \$F\_A(Q^2)=\sum\_k a\_k z^k\$ with about 5–7 free coefficients tuned to reproduce the deuterium bubble chamber measurements.

**Alternative Models:** The traditional approach has been a **dipole form factor**, \$F\_A(Q^2) = \frac{g\_A}{(1+Q^2/M\_A^2)^2}\$, with an adjustable axial mass \$M\_A\$. Dipole is an empirical ansatz (it would be exact if the nucleon axial charge distribution were a simple exponential). Older generators and experimental fits often treated \$M\_A\$ as a fit parameter (historically around 0.95–1.05 GeV from deuterium data, but higher if nuclear effects not included). Another alternative is to use **lattice QCD** calculations or other models (but lattice results for \$F\_A\$ have not yet achieved percent-level precision in the few-GeV range, so generators rely on fits to data). The \$z\$-expansion offers more flexibility than dipole and avoids model bias, at the cost of introducing multiple parameters that need data constraints.

**Comparison to Data:** By construction, the \$z\$-expansion fit **reproduces the neutrino-scattering data on deuterium** (e.g. from ANL and BNL bubble chamber experiments) within uncertainties. It also yields an axial form factor consistent with modern constraints like the nucleon axial radius from lattice QCD and muon capture. In practical GENIE simulations, using the \$z\$-exp fit instead of a dipole will give slightly different QE cross-section shapes: for example, the \$z\$-exp might produce a gentler \$Q^2\$ fall-off than a dipole with \$M\_A=1.0\$ GeV (Meyer *et al.* found an axial radius somewhat larger than dipole’s, implying a bit slower form factor decrease at intermediate \$Q^2\$). This can increase QE cross sections by \~10–20% in some energy ranges. The \$z\$-expansion’s advantage is that it comes with a well-defined uncertainty band, allowing propagation of form-factor uncertainties into cross-section uncertainties – something a single dipole \$M\_A\$ value doesn’t provide. Overall, both dipole and \$z\$-expansion fits describe existing deuterium data reasonably (data errors were large), but the \$z\$-expansion is more robust if future precise measurements (e.g. from a hydrogen neutrino experiment) become available, since one can accommodate any observed shape without forcing a dipole form.

## 4. SuSAv2 (Meson-Exchange Currents – 2p2h)

**Physics Process:** The **two-particle–two-hole (2p2h)** mechanism (also called **meson-exchange currents, MEC**) involves interactions where the neutrino interacts with a correlated pair of nucleons in the nucleus, rather than a single nucleon. This often produces two nucleon knockouts (and no pions) and is a source of “QE-like” events that are not true single-nucleon QE. **SuSAv2** is a model that provides both the 1p1h (single nucleon) and 2p2h cross sections based on a Superscaling approach.

**Theoretical Framework:** **SuSAv2** stands for *Superscaling Approach version 2*, developed by the IFIC Valencia and Pavia groups. It builds on the idea of superscaling in electron-nucleus scattering: the nuclear cross sections (after suitable energy scaling) show universal behavior across kinematics. SuSAv2 uses the phenomenological scaling function extracted from electron scattering to predict neutrino-nucleus 1p1h cross sections, and extends it by adding a **microscopic MEC calculation** for 2p2h. The 2p2h part in SuSAv2 is informed by **Relativistic Fermi Gas with two-body currents** (including \$\Delta\$ intermediate states, etc.) and is tuned to electron scattering data at high energy transfer where MEC dominates. In GENIE, SuSAv2 is implemented via pre-computed hadronic tensors for both 1p1h and 2p2h processes, which are then used to generate events. The model effectively includes **both** a QE (1p1h) contribution (similar to a relativistic mean-field model) and a 2p2h contribution that accounts for nucleon-nucleon correlations induced by meson exchange currents (pion exchange between nucleons during interaction). This provides a comprehensive description of *CC0π* (zero pion) events.

**Alternative Models:** The primary alternative MEC model is the **Valencia 2p2h** model (by Nieves *et al.*) which GENIE also supports. Valencia’s MEC is a microscopic calculation of two-body currents (separate from their QE RPA effect) and has been widely used. SuSAv2 offers an independent prediction – it uses the scaling strategy rather than calculating all diagrams from first principles, and it is constrained by electron scattering superscaling data. Another difference: Valencia’s 2p2h was originally implemented for nucleon pairs in specific isospin combinations and has its own strength tuned to fit neutrino data, whereas SuSAv2’s 2p2h is more tied to electron data. Some generators also have empirical MEC tunings (e.g. fit an ad-hoc 2p2h strength to match MiniBooNE). Compared to these, SuSAv2 is considered more **self-consistent** when paired with its 1p1h part (both derived from the same nuclear response formalism). In GENIE’s comprehensive configurations, one can choose either Valencia MEC or SuSAv2 MEC; they both aim to address the excess of low energy transfer events beyond pure QE.

**Comparison to Data:** The inclusion of 2p2h processes is **essential to match many neutrino cross-section measurements**, and SuSAv2 has been shown to successfully reproduce key features. For example, T2K observed that calculations with only QE (even with RPA) underpredict the rate of events – adding the SuSAv2 2p2h component brought the predictions in line with measured muon spectra and proton multiplicities. SuSAv2 (with its 1p1h+2p2h) has been validated against **double-differential cross sections** on carbon, showing good agreement in the “dip” region between QE and \$\Delta\$ resonance where MEC fills in strength. It also reproduces the measured enhancement in nuclear cross sections (e.g. MiniBooNE’s high cross section could be partially explained by MEC). Compared to the Valencia MEC model, SuSAv2 sometimes yields a different distribution of strength (SuSAv2 2p2h tends to concentrate at somewhat higher energy transfer); both models are within present data uncertainties, though detailed comparisons (e.g. MINERvA’s transverse kinematic imbalance measurements) hint at differences in how they spread energy between leptons and nucleons. Overall, SuSAv2 provides a good description of inclusive \$\nu A\$ data (electron-scattering benchmarks and neutrino cross sections), and its implementation in GENIE enables more realistic simulations for experiments like DUNE and T2K that are sensitive to the 2p2h component. In GENIE’s G21\_11 configuration, SuSAv2 1p1h/2p2h is the default, and it was found to improve agreement with, e.g., MicroBooNE and MINERvA data relative to older models.

## 5. Kovalenko Model (QE Charm Production)

**Physics Process:** This refers to **Quasi-Elastic Charm production**, i.e. neutrino interactions that produce charmed hadrons without any other particles (analogous to QE, but the struck particle is a strange quark inside the nucleon which is turned into a charm quark). An example channel is \$\nu\_\mu + s \to \mu^- + c\$ at the quark level, which in a nucleon can manifest as \$\nu\_\mu + N \to \mu^- + \Lambda\_c^+\$ (a charmed baryon) with no additional mesons. It’s a rare process occurring on the nucleon’s strange sea.

**Theoretical Framework:** GENIE models CC QE charm using the **Kovalenko model**, which is inspired by quark-hadron duality arguments. Essentially, it treats the charm-production in the threshold region by averaging over the contributions of charmed hadronic states, akin to how duality models handle resonance and DIS continuity. The model by S. Kovalenko (1990) provides a formula for the cross section of \$\nu\_\mu + s \to \mu^- + c\$ interactions, taking into account heavy quark mass and CKM suppression (the process is Cabibbo-suppressed). GENIE implements this and then **tunes it to NOMAD data**. NOMAD (and earlier experiments) placed limits on such QE charm events. The Kovalenko model includes an effective form factor and uses parton distribution functions via local duality to estimate the cross section in the nonperturbative threshold regime. Because it is normalized to data, GENIE sets the overall rate according to NOMAD’s observed (or upper limit) cross section. Physically, QE charm production is like an analogue of inverse muon decay: a neutrino produces a \$c\$ quark and a muon, with the \$c\$ quark hadronizing into a charmed hadron.

**Alternative Models:** There are few alternatives because of the scarcity of data. One could attempt to extrapolate DIS charm production models down to threshold, but near threshold (\$E\_\nu\sim\$ a few GeV above charm mass) DIS formulas aren’t reliable. Another approach is a *slow rescaling* model (like used historically for heavy quark production in DIS) combined with form factors, but Kovalenko’s model was specifically developed for this kinematic region. If not modeling QE charm explicitly, generators would simply not produce these events or would only produce charm via DIS (which has a higher energy threshold \~\$E\_\nu > 10\$ GeV to produce \$D\$ mesons, etc.). Kovalenko provides a dedicated treatment for the low-energy regime. As data improves (e.g. DsTau or MINERvA might provide new info on charm), the model could be refined, but currently it’s essentially the only practical choice implemented.

**Comparison to Data:** QE charm production is a **tiny contribution** to total cross sections. The model is tuned to NOMAD’s search, which reported no significant signal and set an upper limit on the cross section. GENIE’s tuned model hence produces a very low rate consistent with that limit. This means in simulations, QE charm events are extremely rare. The kinematics from the model suggest that the outgoing \$\Lambda\_c\$ (or other charmed baryon) carries most of the neutrino energy (since it’s a two-body final state, like QE), and the muon is relatively low-energy – features that could help distinguish it experimentally. As of now, no experiment has conclusively observed CC QE charm on nucleons (only heavier targets like neon with bubble chambers gave some hints). The Kovalenko model predictions have large uncertainties (due to unknown form factors, the model assumes duality with DIS charm). Within those, it does not conflict with existing data (the data basically say the cross section must be \$\lesssim 10^{-3}\$ of CC interactions at a few tens of GeV). Should future experiments (e.g. DUNE) see evidence of QE charm (like \$\Lambda\_c\$ production), the model will need retuning. In summary, GENIE’s Kovalenko model provides a way to generate these rare events in line with theoretical expectations and current limits, ensuring such processes are not completely omitted in high-energy simulations (e.g. NOvA, Minerva at 50 GeV where even a tiny fraction might matter for charm physics).

## 6. Pais Model (QE Strange Hyperon Production)

**Physics Process:** This refers to **quasi-elastic production of strange baryons**, specifically the associated production of a \$\Lambda\$ or \$\Sigma\$ hyperon in neutrino interactions with no pions in the final state. An example is \$\nu\_\mu + p \to \mu^- + p + K^+\$ (which effectively is \$\nu\_\mu + d (uud)\$ turning a \$d\$ into an \$u\$ and creating an \$s\bar{s}\$ pair, yielding \$\mu^- + uuds (\Lambda)\$ + \$\bar{s}u (K^+)\$). However, in GENIE’s context the “QEL strange” likely means the process \$\nu\_\mu + n \to \mu^- + \Lambda^0\$ (with an accompanying proton spectator in nuclear interactions) or similar – essentially a CC interaction that produces a hyperon (S=–1 baryon) without an extra meson (**associated production** always creates a kaon, so strictly speaking a kaon is produced too, but perhaps it’s considered part of the QE system here). The implemented model is from a 1971 paper by Abraham Pais.

**Theoretical Framework:** GENIE uses the model by **A. Pais (Annals Phys. 63 (1971) 361)** to simulate these CC hyperon productions. Pais’s model was formulated for strangeness-changing weak interactions at low energies, using an analogy with nuclear beta decay and symmetries of the weak current. It likely assumes an axial-vector form factor and vector form factors for the \$N\to Y\$ (nucleon to hyperon) transition, using SU(3) symmetry to relate them to nucleon form factors. The process can be viewed as quasi-elastic scattering off a bound strange quark in the nucleon sea (similar to QE charm but for strange) or as associated production at threshold. The Pais model provides differential cross sections for reactions like \$\nu + N \to \mu + Y\$ (with a kaon produced to conserve strangeness, implicitly). In GENIE, this is treated as an exclusive two-body reaction: e.g. \$\nu\_\mu + n \to \mu^- + \Lambda\$ (which in free space would actually require a \$K^+\$ to conserve quantum numbers, but within a nucleus the \$K^+\$ may be reabsorbed or effectively it focuses on the primary weak vertex). The model includes form factors (possibly assuming Cabibbo theory and SU(3) couplings) to estimate the rate. It was not used in GENIE until v2.12, when hyperon production was added.

**Alternative Models:** Like QE charm, there are few modern treatments of low-energy hyperon production. One could simulate it via resonance production (e.g. neutrino producing a \$\Sigma^\*\$ resonance that decays into \$\Lambda K\$) or as DIS strangeness (at higher energies producing strange mesons and baryons). In fact, older generators often did *not* have a dedicated QE hyperon channel – the events would appear either in associated production (treated as a kind of shallow inelastic process) or not at all. The Pais model is an old but straightforward approach using weak current algebra techniques available at the time. No other dedicated model (e.g. from Lagrangian hyperon production calculations) is commonly in use. If not using Pais, one might rely on experimental data parameterization: bubble chamber experiments (like BEBC, FNAL 1980s) measured some rates of \$\Lambda\$ production in \$\nu\$–Neon interactions. However, those include mostly associated production with a kaon. Pais’s model essentially gives a **baseline prediction** consistent with early theoretical expectations.

**Comparison to Data:** The rate of CC hyperon (with kaon) production in neon was found to be small – on the order of a few \$10^{-2}\$ of CC interactions at \$E\_\nu\sim20\$ GeV. GENIE’s Pais model is tuned qualitatively to those observations: it ensures that a few percent of interactions can produce strange particles (K, \$\Lambda\$) in events with no pions. Because hyperons decay (e.g. \$\Lambda \to p\pi\$) and kaons can be absorbed, these processes contribute to final states that can mimic QE or 2p2h (one or two nucleons, no pion, plus possibly undetected \$K\$ or strange remnants). There isn’t a recent precise dataset to validate the model’s differential predictions. However, integrated strange production rates from GENIE (with Pais) are in reasonable agreement with old bubble chamber results on neon. For modern experiments, this channel is very rare and often below detection thresholds (kaons are soft). The Pais model’s form factors and assumptions likely carry large uncertainties, but given the small contribution, it’s not yet an area of active tuning. In summary, the model is **empirically adequate**: it produces associated \$\Lambda K\$ events in low numbers, roughly matching the few measurements we have, thus preventing an underestimation of strange-particle backgrounds. If future experiments measure CC hyperon production (e.g. MINERvA or DUNE could detect \$K^+\$), the model may need updates. For now, it fills an otherwise missing piece of CC interaction physics using a classic theoretical approach.

## 7. Berger–Sehgal Model (Resonance & Coherent Pion Production)

**Physics Process:** This covers two related processes: **neutrino-induced baryon resonance (RES) production** (e.g. \$\nu\_\mu + p \to \mu^- + \Delta^{++}\$, which decays to \$p+\pi^+\$) and **coherent pion production** (e.g. \$\nu\_\mu + \text{C}^{12} \to \mu^- + \pi^+ + \text{C}^{12}\$, where the nucleus remains in ground state). GENIE uses updated formulations by Berger and Sehgal for both. Resonant production involves the excitation of nucleon resonances (like \$\Delta(1232)\$, \$N^\*(1440)\$, etc.) by the weak current, leading to pions in the final state. Coherent production involves the neutrino interacting collectively with the nucleus (via meson-exchange, effectively) to produce a pion without breaking the nucleus.

**Theoretical Framework (Resonances):** The classic model for single pion resonance production is the **Rein–Sehgal model (1981)**, which assumes an isotropic decay of resonances in their rest frame, uses helicity amplitudes from electroproduction, and neglects lepton mass. **Berger & Sehgal (2007/2008)** introduced refinements to this model. In particular, they included the **pion pole contribution** to the hadronic axial current (important for accurate form of the \$N \to N^\*\$ axial transition). This is often referred to as the KLN (Kuzmin–Lyubushkin–Naumov) + Berger–Sehgal (BS) model: KLN had updated the lepton mass and form factors, and B–S further added the constructive interference from the pion-pole term (PCAC-like contribution) in the axial form factor of resonances. The result is a modified cross-section formula for resonant production that reduces the predicted cross section for some channels (the pion pole term interferes and can suppress strength at low \$Q^2\$). GENIE in some configurations uses these Berger–Sehgal updated resonance calculations instead of the original Rein–Sehgal. The vector form factors are still taken from electroproduction data; the axial form factors are usually assumed dipole (with an adjustable axial mass for resonances, \$M\_A^{RES}\$, often tuned around 1.12 GeV). B–S also explicitly include the finite charged-lepton mass in kinematics, which is important for \$\nu\_\mu\$ at low energies (Rein–Sehgal had assumed massless leptons).

**Theoretical Framework (Coherent):** Coherent pion production is modeled using the **Berger & Sehgal (2009) PCAC model**. This model uses the Partially Conserved Axial Current (PCAC) hypothesis to relate the neutrino coherent pion cross section to the measured \$\pi\$–nucleus elastic scattering cross section. Berger and Sehgal updated the old Rein–Sehgal coherent model by incorporating lepton mass effects and using modern pion-nucleus cross section data (they fit a superposition of coherent production amplitudes to available \$\pi\$–carbon data). The result is a prediction that for \$\nu\_\mu\$ at low energies, coherent production is strongly suppressed for \$\pi^+\$ (especially just above threshold) because of the muon mass, which fixed an overestimation in the older model. GENIE switched to this Berger–Sehgal coherent model as it provides better agreement with experimental non-observation of low-energy coherent pions (e.g. at MiniBooNE energies, B–S predicts a low rate consistent with what was observed, whereas original Rein–Sehgal had predicted a significant rate that wasn’t seen).

**Alternative Models:** For resonances, aside from Rein–Sehgal and its Berger–Sehgal improvements, there are more sophisticated approaches (e.g. dynamical models by Sato-Lee or recent models with helicity amplitudes from MAID). Some generators (NEUT) use their own tuned isobar models. However, Rein–Sehgal has been the workhorse and Berger–Sehgal is essentially an augmentation of it. Another alternative is to use a more modern resonance parameterization like **Giessen or ANL/BNL fits**; GENIE’s current approach is to stick with Rein–Sehgal structure but apply corrections (like B–S). For coherent production, alternatives include microscopic models (e.g. Alvarez-Ruso’s microscopical model with detailed nuclear ground-state or the K2K model) and the original Rein–Sehgal model. The Berger–Sehgal coherent model largely supersedes Rein–Sehgal (1983) by fixing its known issues (like ignoring lepton mass). Experiments (MINERvA, T2K) also compare to a model by **Rein–Sehgal with lepton mass correction** (an intermediate fix) and to fully microscopical models; B–S tends to agree with data at least in normalization.

**Comparison to Data:** *Resonance production:* GENIE with the Berger–Sehgal resonance model yields cross sections similar to the older model for the dominant \$\Delta(1232)\$, but with some reductions at low \$Q^2\$ due to the pion-pole term. This generally improves agreement with bubble chamber data on \$\nu p \to \mu^- p \pi^+\$, which indicated a slightly lower cross section at low \$Q^2\$ than a simple dipole form predicted. Modern MINERvA data on resonance production (e.g. \$1\pi\$ production) have shown the need for tunes (usually an overall normalization tweak and adjusting \$M\_A^{RES}\$). Both Rein–Sehgal and Berger–Sehgal can be tuned to data; the Berger–Sehgal version, with \$M\_A^{RES}\approx1.12\$ GeV, generally fits data with a smaller tune factor. For example, GENIE’s tuned model G18\_02 (used in some MINERvA fits) uses B–S and achieved better agreement with measured pion kinematic distributions than the older model. *Coherent production:* The Berger–Sehgal coherent model correctly predicted that SciBooNE and MiniBooNE would observe **almost no \$\pi^+\$ coherent events at \$E\_\nu\sim1\$ GeV**, whereas the original model had predicted \~30% of all \$\pi^+\$ from coherent. When MINERvA later measured coherent \$\pi^\pm\$ at \$E\_\nu\sim3-5\$ GeV, the observed cross sections were consistent with the B–S model within errors. In GENIE, moving from Rein–Sehgal to Berger–Sehgal coherent required no retune; it naturally aligned with data. Overall, these updates by Berger and Sehgal have **brought GENIE’s pion production closer to experimental reality**. There remain some discrepancies in detailed distributions (e.g. angular distributions of pions from resonance decays might need lepton mass effects or better hadronic form factors), and GENIE allows choosing between models for systematic studies. But with Berger–Sehgal, simulations avoid the gross overpredictions of coherent scattering at low energy and include a more realistic resonance axial form factor (pion-pole contribution that reduces cross section), improving the fidelity of neutrino event generators in the 1–5 GeV range.

## 8. Bodek–Yang Model (SIS/DIS Region)

**Physics Process:** This model governs **inelastic neutrino scattering at intermediate to high energies**, specifically the transition from the shallow-inelastic (resonance) region to deep-inelastic scattering (DIS). It provides a unified formula for **DIS structure functions** that can be used down to low \$Q^2\$ and moderate invariant masses. In GENIE, Bodek–Yang is used for both the **SIS (shallow inelastic)** region (W just above resonance region, e.g. 1.6–2.5 GeV) and the full DIS region (higher W). Essentially, whenever the interaction is not QE or resonance or coherent – i.e. multi-pion or quark-level DIS – the cross section is computed with Bodek–Yang structure functions.

**Theoretical Framework:** The **Bodek–Yang model** (2004) is an **improved leading-order PDF-based DIS model with low-\$Q^2\$ modifications**. It starts with standard parton distribution functions (e.g. GRV98 LO PDFs for nucleons) to get the baseline \$F\_2\$ and \$xF\_3\$ structure functions for neutrino scattering, then introduces an effective scaling variable \$\xi\_w\$ that accounts for target mass and higher-twist effects at low \$Q^2\$. By using \$\xi\_w\$ instead of Bjorken \$x\$, and adding separate corrections for \$u,d\$ valence quarks and sea quarks at low \$Q^2\$, the model is able to **bridge the gap between DIS data at high \$Q^2\$ and resonance data at low \$Q^2\$**. Bodek–Yang essentially blends in the resonance contribution by modifying the DIS structure functions such that they emulate the averaged resonance strength (this exploits quark-hadron duality: the average over resonances follows PDFs). The model was fit to charged-lepton scattering data (SLAC, BCDMS, NMC) across a wide range, including the resonance region data from JLab, as well as neutrino data (CCFR). In GENIE, the implementation uses these effective structure functions to calculate differential cross sections for \$\nu N \to \ell X\$ for all W above the resonance cutoff (\~1.7 GeV by default). There is a smooth handoff: at W just above the \$\Delta\$ region, Bodek–Yang’s modifications ensure no double counting with explicit resonances (GENIE typically subtracts out the low-W resonance part or uses a transition blending). Additionally, GENIE includes an overall normalization factor for DIS that was historically applied to match high-energy \$\nu\$ data at 100 GeV (Bodek–Yang LO PDFs underpredict slightly, so a scale factor \~1.02–1.1 is used).

**Alternative Models:** If not using Bodek–Yang, one could use a pure parton model (e.g. GRV98 or CTEQ PDFs) with corrections for target mass (the *Nieves* group has a model, or the AKP20 PDFs etc.). However, pure PDF models tend to fail in the low \$Q^2\$, low \$W\$ region – they don’t account for resonances. Another approach is to explicitly simulate resonances up to a higher W and then switch to DIS PDFs at some cutoff (this still leaves a gap unless one simulates *all* resonances up to W\~2.5 GeV, which is impractical). The **Bodek–Yang model’s strength** is it uses duality to effectively fill in that shallow-inelastic region continuously. Other generators have implemented similar ideas (NEUT uses Bodek–Yang too; GIBUU uses a generalized model with vector dominance at low \$Q^2\$). Bodek–Yang has been updated over time (2007, 2011 updates with small tweaks to parameters); GENIE’s model is based on these works and is tuned as part of overall fits.

**Comparison to Data:** The Bodek–Yang model was constructed to **fit all available data** on inclusive scattering. It indeed provides a good description of measured \$F\_2\$ structure functions from the DIS region down to \$Q^2 \approx 0.5\$ GeV\$^2\$. In GENIE, this translates to predicted cross sections that match the old **bubble chamber neutrino data** at medium energies (\~10–30 GeV) fairly well after a small normalization tweak. For example, the model reproduces the observed transition: the resonance “bump” structure is smeared out in the inclusive cross section and Bodek–Yang follows that smooth trend. When GENIE was tuned to NOMAD and MINERvA data, the Bodek–Yang parameters (like the low-\$Q^2\$ correction terms) were within uncertainties, indicating no large deviation from those datasets. At very high energies (\$E\_\nu > 100\$ GeV), Bodek–Yang (with LO PDFs) slightly underestimates cross sections; GENIE applies a factor (e.g. \~1.03 at 100 GeV) to match the precise value of \$\sigma\_{\text{tot}}\$ observed. This factor accounts for higher-order QCD and such not in the LO PDF. Once applied, GENIE’s DIS matches the high-energy neutrino total cross sections on isoscalar targets within \~1–2%. In the few-GeV regime, comparisons to MINERvA’s structure function data (likely forthcoming) will test the Bodek–Yang model more; but so far, it captures the general behavior of **inclusive multi-hadron production**. One limitation: the model by itself doesn’t give exclusive hadrons, so GENIE still relies on a hadronization model (AGKY/PYTHIA) to generate final states after using Bodek–Yang to get the inclusive cross section. Provided that coupling is done carefully (avoiding double counting resonances), the result is a smooth total cross section that respects both DIS data and low-W physics. In summary, Bodek–Yang is **well validated** against existing data and remains a standard for neutrino DIS simulation.

## 9. Aivazis–Olness–Tung (DIS Strange/Heavy Quark Production)

**Physics Process:** This model governs **heavy quark production in DIS**, specifically neutrino-induced charm production from strange (or anti-strange) quarks in the nucleon. In high-energy neutrino DIS, when a neutrino interacts with an \$s\$ quark via \$W^+\$ exchange (\$\nu\_\mu + s \to \mu^- + c\$), a charm quark appears in the final state. Similarly, \$\bar\nu\$ can hit an \$\bar{s}\$ to produce \$\bar{c}\$. These are part of the DIS scattering (one parton in, one heavy parton out). The model by Aivazis, Tung, and Olness provides a framework to calculate such processes taking into account the heavy quark mass (charm in this case) within QCD.

**Theoretical Framework:** The **Aivazis–Olness–Tung (AOT)** scheme is a well-known general-mass **ACOT** prescription in perturbative QCD for dealing with heavy quark parton distributions. In simpler terms, it handles the transition between regimes where the heavy quark (charm) is treated as a parton in the nucleon at high \$Q^2\$ and where it’s kinematically forbidden at low \$Q^2\$. GENIE uses this model to compute the **charm production structure functions** and cross sections for DIS. The AOT model (Phys. Rev. D50 (1994)) provides formulae for the leptoproduction of heavy quarks, including both **charged-current** (for neutrinos) and electromagnetic (for charged leptons) processes. It includes contributions from diagrams like: (1) \$s(\bar{s})\$ in the nucleon, struck by \$W\$, produces \$c(\bar{c})\$ – here the strange PDF is used but modified by mass-dependent coefficient functions; (2) \$W\$-gluon fusion: the \$W\$ boson can interact with a gluon splitting into \$c\bar{s}\$, etc. ACOT scheme properly accounts for **threshold effects** (the charm PDF is zero below its threshold) and for **mass suppression** in the partonic cross sections. GENIE’s implementation uses proton and neutron PDFs (with strange sea content) and then the AOT formulas to calculate differential cross sections \$d^2\sigma/(dx,dy)\$ for producing charm. It also includes an empirical **branching fraction** for how often a given neutrino DIS will produce a charm – in fact GENIE takes charm production fractions from experimental data. By default, it uses charm mass \$m\_c = 1.43\$ GeV and Peterson fragmentation to produce charmed hadrons (like \$D\$ mesons or \$\Lambda\_c\$) from the produced \$c\$ quark.

**Alternative Models:** Historically, heavy quark production in neutrino DIS was treated by a simpler **“slow rescaling”** model: using light-quark PDFs but scaling the Bjorken-\$x\$ to account for the heavy mass (introduced by Duke & Owens, or earlier by Barnett). The Aivazis–Tung–Collins (ACOT) scheme is a more rigorous general-mass perturbative approach and is now standard in PDF sets (many modern PDF fits like CT14 incorporate general-mass treatments). One alternative scheme is the **Thorne–Roberts (TR’ scheme)** or the **FONLL scheme** by Cacciari *et al.*, but those are similar in spirit. For GENIE’s purposes, AOT is appropriate and probably taken from the PDF library. If one did not explicitly include this, one might simply turn on the charm PDF above threshold (fully massless scheme) which would overestimate production near threshold. Or one might use only slow-rescaling formula from the 1980s, which is less accurate. Thus AOT/ACOT is the preferred method as it **matches QCD calculations across all \$Q^2\$**.

**Comparison to Data:** The AOT heavy quark model (with appropriate PDFs and fragmentation) does a good job reproducing data from CCFR, NuTeV, and NOMAD on charm production. These experiments measured rates of \$\nu\_\mu + N \to \mu^- D\_s^+ X\$ or dimuon events (muon from primary vertex and muon from charm decay) to infer strange quark distributions. GENIE uses external inputs: the **charm production fraction** (the probability that a given DIS event produces a charm) is set to match data. For example, CCFR/NuTeV found the strange quark content of the nucleon to be about 40% of the down sea, and GENIE’s model is consistent with that. When simulating, GENIE will generate a charmed hadron in DIS according to these fractions – e.g. roughly 1 in 20 neutrino DIS interactions produce a charm at a few tens of GeV (depending on \$x\$ and \$Q^2\$). The AOT cross section formula itself reproduces the measured **dimuon cross sections** as a function of energy and \$x\$ within uncertainties. For instance, NOMAD’s results on \$\nu\_\mu\$ induced charm (which are at higher energy) agree with next-to-leading order ACOT predictions to \~10%. GENIE’s tune sets the charm mass and PDF such that the total charm cross section is tuned to NOMAD/CHORUS region. It also by default includes both **Peterson fragmentation** (the default) and an option for Collins-Spiller fragmentation for charmed quarks, which govern the distribution of energy carried by the resulting \$D\$ meson or \$\Lambda\_c\$. Those fragmentation parameters were historically tuned to EMC data in \$e^+e^-\$. Overall, the heavy quark DIS model in GENIE is **consistent with world data on neutrino charm production**, and it provides a vital component for predictions at moderate-to-high energies. For experiments like MINERvA or DUNE, accurate strange/charm production modeling is important for event classification (e.g. charm can mimic certain signals), and the AOT model is up to the task, with uncertainties that can be evaluated by varying the strange PDF or charm mass.

## 10. AGKY Model (Hadronization)

**Physics Process:** After a neutrino interacts deep-inelastically with a nucleon (or in any inelastic channel that produces a hadronic system), the **hadronization model** is responsible for producing the final-state hadrons from the outgoing quarks and gluons. The **AGKY model** is GENIE’s hadronization framework, covering how quarks produced in DIS form mesons, baryons, etc. It specifically addresses the hadronic shower in the energy regime relevant to neutrino experiments (from low invariant mass just above resonances up to high DIS energies).

**Theoretical Framework:** **AGKY** is a **hybrid hadronization model**. At low invariant mass \$W\$ (near the threshold for multi-hadron production, say \$W \lesssim 2–3\$ GeV), hadronization is handled by a custom phenomenological model based on **Koba–Nielsen–Olesen (KNO) scaling**. This means it uses observed multiplicity distributions and inclusive particle ratios from old experiments to generate a modest number of hadrons (usually one or two pions, maybe a kaon, etc., plus a nucleon) in the final state. At high invariant mass (\$W\$ above a certain cutoff), hadronization is done by the **PYTHIA/JETSET** Lund string model. The key is a **transition region** \$W\_{\text{min}}^{\text{tr}} < W < W\_{\text{max}}^{\text{tr}}\$ (default roughly 2.3–3.0 GeV) over which GENIE linearly interpolates between the low-\$W\$ KNO model and the high-\$W\$ PYTHIA model. This ensures continuity in observables as \$W\$ increases. In practice:

* **Low \$W\$ (AGKY-KNO):** Typically produces exactly one baryon (nucleon or \$\Delta\$ which decays) and a few mesons such that charge, baryon number, and strangeness are conserved. The multiplicity distribution of pions follows KNO scaling (a scaling law observed in multiparticle production). Parameters for the multiplicity (like the mean multiplicity as a function of \$W\$) are tuned to bubble chamber data (e.g. \$\langle n\_\pi \rangle\$ vs \$W\$ from old ANL/BNL data). Hadron types (π^+, π^0, π^-, K, etc.) are assigned according to probabilities also taken from data. Then their 4-momenta are sampled isotropically in the hadronic center-of-mass or according to phase space, with some additional constraints to mimic known momentum distributions.
* **High \$W\$ (PYTHIA):** The standard Lund string fragmentation takes over. The quark struck by the neutrino and the target remnant quark system are strung together, and string breaking yields multiple hadrons (as in \$e^+e^-\$ or \$pp\$ collisions). GENIE uses PYTHIA with parameters tuned by the NOMAD and other data (the “AGKY tune”). It allows many hadrons including multiple pions, kaons, and baryon-antibaryon pairs once \$W\$ is large.

The **transition window** (2.3–3.0 GeV) means, for example, at \$W=2.3\$ GeV, 100% events use KNO model; at \$W=3.0\$ GeV, 100% use PYTHIA; in between, a mix. This avoids a sudden discontinuity in multiplicity when switching models.

**Alternative Models:** Other neutrino generators sometimes rely purely on PYTHIA (or HERWIG) from quite low \$W\$, which can be problematic because PYTHIA is tuned for high energies and might not handle threshold production correctly. Another alternative for very low \$W\$ is to use explicit resonance decays (GENIE already does for \$W<1.7\$ as “resonance” events). The AGKY model is unique in bridging that gap empirically. Some older codes (NEUGEN) had similar hybrid models, and indeed AGKY was initially developed for NEUGEN and taken into GENIE. If one did not use AGKY, a simple approach might be to **just use PYTHIA for all DIS** and a custom one-pion model for the region below \$W=2\$ GeV. But PYTHIA would significantly underproduce events with low multiplicity at \$W\sim2\$ GeV because it would tend to produce 2-3 pions instead of 1 (given how it’s tuned to higher energy). AGKY’s empirical KNO model ensures that, for example, at \$W=2\$ GeV, the most likely outcome is 1 pion + 1 nucleon (which matches bubble chamber observations). Another approach could be the **Fermi break-up model** for nuclear fragmentation, but that’s more for nuclear de-excitation than primary hadronization.

**Comparison to Data:** The AGKY model was **extensively validated against 1970s–80s bubble chamber neutrino data** (on hydrogen, deuterium, neon). Key benchmarks include:

* **Charged multiplicity distributions:** AGKY reproduces the average charged pion multiplicity \$\langle n\_{\pi} \rangle\$ as a function of \$W\$, and the distribution around that average, in good agreement with data. For instance, at \$W\approx2\$ GeV, data show mostly 1 or 2 pions; AGKY yields that, whereas a pure string model might skew to higher multiplicities.
* **Strange particle production:** The model includes “associated production” of \$K\$ and \$\Lambda\$ in the KNO part. It was noted that PYTHIA (tuned to high energy) underproduced kaons at low \$W\$. AGKY’s KNO-based component was adjusted to fit the observed rates of \$K^0\$, \$K^+\$, and \$\Lambda\$ at low energies. This yields reasonable strange particle yields, whereas unmodified PYTHIA would underestimate them.
* **Hadron kinematic distributions:** AGKY (especially with PYTHIA for high \$W\$) was tuned to bubble chamber data on momentum spectra of pions and protons. For example, the so-called “seagull effect” – the increase of average \$p\_T\$ with multiplicity (or with \$W\$) and then a flattening – is reproduced by AGKY. The model gets the \$p\_T\$ spectra reasonably (in the naive quark model, low-\$W\$ hadrons have primordial \$p\_T\$ \~ 0.3 GeV, which AGKY reflects; at higher \$W\$, QCD radiation gives a bit higher \$p\_T\$, which PYTHIA covers).
* **Comparison with data:** In the 1–5 GeV region, experiments like T2K and MicroBooNE now can measure final-state multiplicities. AGKY’s predictions, when combined with FSI, have been generally consistent with these measurements within errors. For example, the observed proton and pion yields in MINERvA for DIS events align with GENIE (which uses AGKY + FSI) after some tuning. The model’s global tuning (AGKY global tune 2021) further improved the agreement by adjusting PYTHIA parameters slightly.

In summary, the AGKY hadronization model provides **satisfactory agreement with available data** on hadron multiplicities and kinematics. It smoothly joins the low-energy empirical regime to the high-energy perturbative regime, which is crucial for long-baseline neutrino experiments that span a few GeV to tens of GeV. The model is continuously checked against new data; for instance, the GENIE 3 tunes included refinements to AGKY parameters to better fit MINERvA and T2K multiplicity data. Thanks to its design, **AGKY ensures that neutrino event generators produce realistic final states from threshold to high energy**, an important factor for detector simulations and reconstruction (since particle multiplicities and spectra affect observable distributions).

## 11. *hA* Intranuclear Cascade (Final-State Interactions)

**Physics Process:** After the primary neutrino-nucleon interaction produces outgoing hadrons inside a nucleus, those hadrons can undergo **Final-State Interactions (FSI)** as they propagate out of the nucleus. FSI include processes like secondary collisions of pions or nucleons with the nuclear medium: absorption, charge exchange, elastic scattering, and inelastic scattering. The **hA model** in GENIE is one of the intranuclear hadron transport models that simulate these FSI effects.

**Theoretical Framework:** The **hA model** (sometimes called INTRANUKE/hA) is a **parametrized intranuclear cascade** model. It is “semi-empirical”: rather than simulating every nucleon and hadron step-by-step, it uses the measured interaction probabilities of hadrons in nuclear matter to decide outcomes. Concretely, for each hadron (nucleon or meson) leaving the primary vertex, hA assigns an interaction length based on the total cross section in nuclear matter and decides if it interacts before leaving the nucleus. If it does, the type of interaction (e.g. pion absorption vs scattering) is chosen according to probability distributions that come from data (e.g. \$\pi\$-Fe cross sections). The kinematics of the hadron after interaction are treated simply (e.g. an absorbed pion disappears; an elastically scattered nucleon has its direction randomized and energy reduced, etc.). The model is called “hA” because it uses data-driven cross sections for **h**adrons on **A**-nuclei. It is calibrated primarily to **pion–nucleus and nucleon–nucleus data** up to about 1.2 GeV kinetic energy. Above that, it extrapolates or uses results from a more detailed cascade (CEM03) but normalized to known data where available. Key features:

* It treats pions and nucleons (and kaons, et al.) separately. It uses the same cross section for \$\pi^+\$ and \$\pi^-\$ (assuming isospin symmetry in an isoscalar nucleus). Similarly for proton vs neutron.
* Reaction channels considered include: elastic scatter, inelastic (charge exchange for pions, pion production for nucleons), absorption (for pions, e.g. \$\pi N N \to N N\$), and **quasi-elastic** knockout (for nucleons, scattering off another nucleon and knocking it out). The model pre-defines probabilities for each channel as a function of energy, based on external data.
* The nuclear medium is implemented via an **effective density** (interaction probabilities scaled by nuclear size) and an **\$A^{2/3}\$ scaling** for cross sections when data on different nuclei is extrapolated. The hA model was initially tuned to iron (Fe) data because of MINOS’s interest, and it assumes isoscalar targets unless adjusted.

The *hA2010* is the version used through GENIE 2.x, which is what we describe. It’s simple, using one mean free path per hadron and randomizing outcomes.

**Alternative Models:** GENIE also provides an alternative internal cascade called **hN** (full intranuclear cascade), as well as interfaces to external cascades like **GEANT4 Bertini** or **INCL++**. The hN model simulates stepwise propagation of hadrons through the nucleus, with differential cross sections, making it more microscopic than hA. However, hN is slower and was introduced later. The **hA model** was the default for many years because of its speed and the fact that it **preserves overall topology** well (it’s tuned to get average absorption, charge exchange rates right). Other generators use different cascades: NEUT has its own Oset-based cascade (similar spirit to hA, data-driven); NuWro uses a full cascade; GEANT4’s cascades are fully detailed. Compared to a full cascade, hA might not reproduce angular distributions or correlations as well, but it gets inclusive re-scattering rates reasonably.

**Comparison to Data:** The hA model’s parameters were tuned to reproduce hadron scattering data on nuclei for pions and nucleons up to \~1 GeV. For example, it reproduces the **pion absorption fraction** in carbon, oxygen, and iron: about \~30% of pions of a few hundred MeV are absorbed (turning into nucleons). It also reproduces charge exchange fractions (e.g. \$\pi^+ n \to \pi^0 p\$ turning a \$\pi^+\$ into a \$\pi^0\$ inside) to within 10-20% of data. When comparing GENIE predictions to experiments:

* **Final state multiplicities:** hA ensures that, say, the number of final-state pions in QE vs resonance events matches observed distributions after FSI. If a \$\Delta\$ resonance produces a \$\pi^+\$ in a nucleus, hA might absorb it 20% of the time or charge-exchange it to \$\pi^0\$ 15% of the time, etc., which matches pion rescattering data. As a result, GENIE predictions of pion yields in detectors have been in line with bubble chamber measurements on heavy targets after applying hA.
* **Hadron kinematics:** Because hA is not a true transport simulation, some differential distributions (e.g. the outgoing pion energy spectrum after FSI) can be slightly off. However, hA was designed to be **“sanity checked”**: for instance, it does not allow energy non-conservation; it tends to knock out nucleons when pions are absorbed, approximating the observed nuclear breakup. Comparisons with more detailed cascades (GEANT4) show that hA gets the overall shape of exiting particle energy spectra reasonably, though it may not produce, for example, low-energy de-excitation photons or very low energy nucleons (hA focuses on primary FSI).
* **Efficiency in Oscillation Experiments:** The impact of hA has been studied by experiments like MiniBooNE, MINERvA, T2K by varying FSI parameters. hA’s default predictions generally fell within their error bands. For example, MINERvA’s measured proton momentum distribution in QE events could be reproduced by GENIE with either hA or hN; differences were smaller than experimental uncertainties.

The GENIE manual notes that hA is **fast and straightforward but not the most accurate**. Indeed, with the advent of hN and GEANT4 cascades, one sees small improvements in matching data (especially for complex final states). But for most observables in the few-GeV range, hA’s simplicity yields results close to full cascade results because it was well tuned. It ensures energy conservation and charge conservation exactly, and double counts nothing by construction. In summary, **hA provides a solid approximation of FSI**: it is normalized to known data on hadron–nucleus interactions, giving GENIE users a fast option with reasonable physical accuracy. It was the default in GENIE v2 (and still widely used in v3 default configurations, e.g. G18\_02a uses hA). Its performance against electron-nucleus data (for validation) is also acceptable – e.g. it can describe the attenuation of pions in (e,e’π) reactions qualitatively. While more refined models exist, hA strikes a pragmatic balance between complexity and agreement with data.

---

Each of the above models addresses a specific aspect of neutrino interaction physics. Together, they form a complete event generator physics suite: the Correlated Fermi Gas sets up initial nucleons; Valencia and SuSAv2 handle 1p1h and 2p2h cross sections (using the z-exp axial form factor); the resonance and DIS models (Berger–Sehgal, Bodek–Yang, AOT) cover higher energy interactions; AGKY turns quarks into hadrons; and finally hA simulates how those hadrons get out of the nucleus. These models have been benchmarked against a broad array of experimental data and are continually refined. By comparing alternative models (as noted for each process), GENIE also quantifies systematic uncertainties. Overall, the chosen models in the GENIE table represent a state-of-the-art compilation that allows comprehensive and realistic neutrino interaction simulations for accelerator-based experiments.
